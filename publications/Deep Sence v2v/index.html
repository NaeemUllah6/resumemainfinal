<!DOCTYPE html>
<html lang="en">

<head>
  <title>João Morais</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <link rel="stylesheet" href="../../assets/css/main.css" />
  <link rel="icon" href="../../images/coffee.jpg" type="image/png" />

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" />
  <noscript>
    <link rel="stylesheet" href="../../assets/css/noscript.css" />
  </noscript>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.css" />
  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    tailwind.config = {
      corePlugins: {
        preflight: false,
      },
    };
  </script>
</head>

<body>
  <div id="wrapper">
    <main class="publicationMain">
      <section class="publicationArticle">
        <a href="/" class="goback">
          <i class="fa-solid fa-arrow-left-long"></i>
        </a>
        <div class="text-center">
          <div class="italic">
            IEEE Transactions on Vehicular Technology (TVT), 2024
          </div>
          <div style="border-bottom: 1px solid gray; padding-bottom: 10px" class="text-[1.8rem]">
            DeepSense-V2V: A Vehicle-to-Vehicle Multi-Modal Sensing, Localization, and Communications Dataset
          </div>
          <div class="text-xl flex flex-wrap justify-center gap-8 px-20 py-4">
            <span><span>João Morais</span><span class="super" style="margin-left: 5px; white-space: nowrap">
                </span></span><span><a href="http://mcrespo.me">Gouranga Charan</a><span class="super"
                style="margin-left: 5px; white-space: nowrap"></span></span><span><a
                href="http://giga.cps.unizar.es/~ajarabo/">Nikhil Srinivas</a><span class="super"
                style="margin-left: 5px; white-space: nowrap"></span></span><span><a
                href="https://redo-sanchez.net/">Ahmed Alkhateeb</a><span class="super"
                style="margin-left: 5px; white-space: nowrap"></span></span>
          </div>
          <div class="flex gap-8 justify-center" style="margin-top: 2ex">
            <span class="spanMobile"><span><span class="super" style="margin-right: 5px"></span>
                <span>Arizona State University.</span></span></span><span class="spanMobile"><span><span
                  class="super" style="margin-right: 5px; font-size: 1"></span>
                <span>Joint first authors</span></span></span>
          </div>
          <!-- <div data-fancybox="gallery"
            data-src="./gallery/Screenshot 2024-09-25 201149.jpg">
            <img src="./gallery/Screenshot 2024-09-25 201149.jpg" alt=""
              class="rounded-md w-full my-4" />
          </div> -->
        </div>
        <figcaption>

        </figcaption>
        <div class="resources_publication">
          <h2>Resources</h2>
          <a class="button_resources" href="https://arxiv.org/pdf/2406.17908"><i
              class="button_icon fa fa-file-pdf"></i><span> <!-- -->Paper (12 MB)<!-- --> </span>
          </a>
          <a class="button_resources" href="#Bibtex"><i class="button_icon fa fa-quote-right"></i><span>
              <!-- -->Cite
              <!-- -->
            </span>
          </a>
        </div>
        <h2 id="Abstract">Abstract</h2>
        <p style="
              text-align: justify;
              text-justify: inter-character;
              text-indent: 1.5rem;
              margin: 0 0 0.5rem 0;
            ">
          High data rate and low-latency vehicle-to-vehicle (V2V) communication are essential
          for future intelligent transport systems to enable coordination, enhance safety,
          and support distributed computing and intelligence requirements. Developing effective
          communication strategies, however, demands realistic test scenarios and datasets.
          This is important at the high-frequency bands where more spectrum is available, yet
          harvesting this bandwidth is challenged by the need for direction transmission
          and the sensitivity of signal propagation to blockages. This work presents the
          first large-scale multi-modal dataset for studying mmWave vehicle-to-vehicle
          communications. It presents a two-vehicle testbed that comprises data from a
          360-degree camera, four radars, four 60 GHz phased arrays, a 3D lidar, and
          two precise GPSs. The dataset contains vehicles driving during the day and
          night for 120 km in intercity and rural settings, with speeds up to 100 km
          per hour. More than one million objects were detected across all images, from
          trucks to bicycles. This work further includes detailed dataset statistics
          that prove the coverage of various situations and highlights how this dataset
          can enable novel machine-learning applications.
        </p>


        <h2>Figures</h2>
        <div class="lg:columns-3 columns-2 gap-2 overflow-hidden">

          <figure data-fancybox="gallery" data-src='./gallery/29.jpg'
            data-caption="Scene setup. The scene is hidden behind a diffuser, with the scene being submerged in a scattering medium">
            <img src='./gallery/29.jpg' alt="" class="rounded-md w-full" loading="lazy" />
          </figure>
          <figure data-fancybox="gallery"
            data-caption="Reconstructions of experimental data. Each column is a different scene. Top: images of the scenes behind the diffuser. Middle: Lindell and Wetzstein reconstructions (CDT). Bottom: our reconstructions using Phasor Fields. The higher frequency of CDT is related to the deconvolution to compensate scattering at the diffuser."
            data-src="./gallery/30.jpg">
            <img src="./gallery/30.jpg" alt="" class="rounded-md w-full" loading="lazy" />
          </figure>
          <figure data-fancybox="gallery" data-src="./gallery/32.jpg"
            data-caption="Reconstructions of the Z-LETTER scene. a) scene with no scattering media. b) reconstructions with scattering media of varying extinction µt (in m−1) and single scattering albedo α. c) reconstructions with scattering media of fixed extinction µt = 1 m−1, varying scattering albedo α, and phase function’s anisotropy g. Phasor Fields is able to reconstruct the scene even in the presence of highly scattering media.">
            <img src="./gallery/32.jpg" alt="" class="rounded-md w-full" loading="lazy" />
          </figure>
          <figure data-fancybox="gallery" data-src="./gallery/35.jpg"
            data-caption="Simulated scenes. We use two simulated scenes: (Left) a single planar letter behind the diffuser (green), and (Right) a closed room with a shelf (red) at the back.">
            <img src="./gallery/35.jpg" alt="" class="rounded-md w-full" loading="lazy" />
          </figure>

          <figure data-fancybox="gallery"
            data-caption="Reconstructions of the Z-LETTER scene in the presence of a scattering medium (µt = 1m−1 and α = 0.83 ) for increasing wavelength λ, with baseline λ0 = 4∆c and ∆c = 0.11m. Higher values of λ result into deeper penetration through the medium, at the cost of lower spatial."
            data-src="./gallery/36.jpg">
            <img src="./gallery/36.jpg" alt="" class="rounded-md w-full" loading="lazy" />
          </figure>
          <figure data-fancybox="gallery"
            data-caption="Reconstruction of the SHELF scene submerged in a medium of increasing density: µt = 0 (no media), µt = 1, and µt = 1.5. In all cases, the scattering albedo is α = 0.5."
            data-src="./gallery/37.jpg">
            <img src="./gallery/37.jpg" alt="" class="rounded-md w-full" loading="lazy" />
          </figure>
          <figure data-fancybox="gallery"
            data-caption="Reconstruction of the SHELF scene submerged in a medium of increasing density: µt = 0 (no media), µt = 1, and µt = 1.5. In all cases, the scattering albedo is α = 0.5."
            data-src="./gallery/39.jpg">
            <img src="./gallery/39.jpg" alt="" class="rounded-md w-full" loading="lazy" />
          </figure>
          <figure data-fancybox="gallery"
            data-caption="Reconstruction of the SHELF scene submerged in a medium of increasing density: µt = 0 (no media), µt = 1, and µt = 1.5. In all cases, the scattering albedo is α = 0.5."
            data-src="./gallery/40.jpg">
            <img src="./gallery/40.jpg" alt="" class="rounded-md w-full" loading="lazy" />
          </figure>
          <figure data-fancybox="gallery"
            data-caption="Reconstruction of the SHELF scene submerged in a medium of increasing density: µt = 0 (no media), µt = 1, and µt = 1.5. In all cases, the scattering albedo is α = 0.5."
            data-src="./gallery/41.jpg">
            <img src="./gallery/41.jpg" alt="" class="rounded-md w-full" loading="lazy" />
          </figure>
          <figure data-fancybox="gallery"
            data-caption="Reconstruction of the SHELF scene submerged in a medium of increasing density: µt = 0 (no media), µt = 1, and µt = 1.5. In all cases, the scattering albedo is α = 0.5."
            data-src="./gallery/42.jpg">
            <img src="./gallery/42.jpg" alt="" class="rounded-md w-full" loading="lazy" />
          </figure>
        </div>
        <h2 id="Figures" class="pt-8">Bibtex</h2>
        <div class="code-container">
          <div class="copy-btn"><i class="fa-regular fa-copy"></i></div>
          <pre>
            <code>@misc{morais2024deepsensev2vvehicletovehiclemultimodalsensing,
              title={DeepSense-V2V: A Vehicle-to-Vehicle Multi-Modal Sensing, Localization, and Communications Dataset}, 
              author={Joao Morais and Gouranga Charan and Nikhil Srinivas and Ahmed Alkhateeb},
              year={2024},
              eprint={2406.17908},
              archivePrefix={arXiv},
              primaryClass={eess.SP},
              url={https://arxiv.org/abs/2406.17908}, 
        }</code>
        </pre>
        </div>
      </section>
    </main>
  </div>
  <!-- BG -->
  <div id="bg" class="publications"></div>

  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.umd.js"></script>

  <script src="../../assets/js/publication.js"></script>
  <!-- <script src="../../assets/js/main.js"></script> -->
</body>

</html>