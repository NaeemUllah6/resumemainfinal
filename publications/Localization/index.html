<!DOCTYPE html>
<html lang="en">

<head>
  <title>João Morais</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
  <link rel="stylesheet" href="../../assets/css/main.css" />
  <link rel="icon" href="../../images/coffee.jpg" type="image/png" />

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" />
  <noscript>
    <link rel="stylesheet" href="../../assets/css/noscript.css" />
  </noscript>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.css" />
  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    tailwind.config = {
      corePlugins: {
        preflight: false,
      },
    };
  </script>
</head>

<body>
  <div id="wrapper">
    <main class="publicationMain">
      <div class="">
        
        <section class="publicationArticle">
          <a href="/" class="goback">
            <i class="fa-solid fa-arrow-left-long"></i>
        </a>
          <div class="text-center">
            <div class="italic">
              ICC 2024
            </div>
            <div style="border-bottom: 1px solid gray; padding-bottom: 10px" class="text-[1.8rem]">
              Localization in Digital Twin MIMO Networks: A Case for Massive Fingerprinting
            </div>
            <div class="text-xl flex flex-wrap justify-center px-20 gap-6 py-4">
              <span><span></span><span class="super" style="margin-left: 5px; white-space: nowrap">
                  </span></span><span><a href="http://mcrespo.me">João Morais</a><span class="super"
                  style="margin-left: 5px; white-space: nowrap"></span></span><span><a
                  href="http://giga.cps.unizar.es/~ajarabo/">Ahmed Alkhateeb</a><span class="super"
                  style="margin-left: 5px; white-space: nowrap"></span></span><span><a
                  href="https://redo-sanchez.net/"></a><span class="super"
                  style="margin-left: 5px; white-space: nowrap"></span></span>
            </div>
            <div class="flex flex-wrap gap-8 justify-center" style="margin-top: 2ex">
              <span class="spanMobile"><span><span class="super" style="margin-right: 5px"></span>
                  <span> Arizona State University, USA</span></span></span><span class="spanMobile"><span><span
                    class="super" style="margin-right: 5px; font-size: 1"></span>
                  <span>
                   </span></span></span>
            </div>
            <!-- <div data-fancybox="gallery"
              data-caption="Bistro: Unbiased rendering of a complex scene with global illumination (22 indirect bounces, resulting in a 48-dimensional integration domain). Traditional Monte Carlo-based rendering results in high variance even with importance sampling techniques. In contrast, our technique combines multiple importance sampling with an adaptive piecewise-polynomial control variate (4D in this example): Our control variate closely approximates the low-frequency regions of the signal, while leaving the high-frequency details on the residual, which is estimated using Monte Carlo integration. This results in lower variance with faster convergence. Except for the reference, the images were generated using 512 samples per pixel."
              data-src="https://mcrespo.me/publications/primary-space-cv/figures/fig_bistroTeaser.jpg">
              <img src="https://mcrespo.me/publications/primary-space-cv/figures/fig_bistroTeaser.jpg" alt=""
                class="rounded-md w-full h-auto my-4" />
            </div> -->
          </div>
          <figcaption>
            <p class="italic" style="
                  text-align: justify;
                  text-indent: 1.5rem;
                  margin: 0px 0px 0.5rem;
                ">
              <!-- <strong> Bistro: </strong> Unbiased rendering of a complex scene
              with global illumination (22 indirect bounces, resulting in a
              48-dimensional integration domain). Traditional Monte
              Carlo-based rendering results in high variance even with
              importance sampling techniques. In contrast, our technique
              combines multiple importance sampling with an adaptive
              piecewise-polynomial control variate (4D in this example): Our
              control variate closely approximates the low-frequency regions
              of the signal, while leaving the high-frequency details on the
              residual, which is estimated using Monte Carlo integration. This
              results in lower variance with faster convergence. Except for
              the reference, the images were generated using 512 samples per
              pixel.
            </p> -->
          </figcaption>
          <div class="resources_publication">
            <h2>Resources</h2>
            <a class="button_resources" href="https://arxiv.org/pdf/2403.09614"><i
                class="button_icon fa fa-file-pdf"></i><span> Paper (4.2 MB) </span></a><a class="button_resources"
              href="data/crespo2021primary_supplemental.pdf"><i class="button_icon fa fa-file-pdf"></i><span>
                Supplemental (28.3 MB) </span></a><a class="button_resources"
              href="https://github.com/mcrescas/viltrum-mitsuba"><i class="button_icon fa fa-code"></i><span> Code
                (Github) </span></a><a class="button_resources" href="#Video"><i
                class="button_icon fa fa-film"></i><span> Video </span></a><a class="button_resources" href="#Bibtex"><i
                class="button_icon fa fa-quote-right"></i><span> Cite </span></a>
          </div>
          <h2 id="Abstract">Abstract</h2>
          <p style="
                text-align: justify;
                text-indent: 1.5rem;
                margin: 0px 0px 0.5rem;
              ">
            Millimeter-wave (mmWave) communication systems
            rely on narrow beams to achieve sufficient receive signal power.
            Adjusting these beams is typically associated with large training
            overhead, which becomes particularly critical for highly-mobile
            applications. Beam selection can benefit from the knowledge of
            user positions to reduce the overhead in mmWave beam training.
            Prior work, however, studied this problem using only synthetic
            data that does not accurately represent real-world measurements.
            In this paper, we revisit the position-aided beam prediction
            problem in light of real-world measurements with commercialoff-the-shelf GPS to derive insights into how
            much beam training
            overhead can be saved in practice. We also compare algorithms
            that perform well in synthetic data but fail to generalize with
            real data, and attempt to answer what factors cause inference
            degradation. Further, we propose a machine learning evaluation
            metric that better captures the end communication system
            objective. This work aims at closing the gap between reality and
            simulations in position-aided beam alignment
          </p>
          <p style="
                text-align: justify;
                text-indent: 1.5rem;
                margin: 8px 0px 0.5rem;
              ">

          </p>
          <!-- <h2 id="Figures" class="pt-4">Video</h2> -->

          <!-- <div class="embla">
            <div class="embla__viewport">
              <div class="embla__container">
                <div class="embla__slide">
                  <div class="embla__slide__number">
                    <div class="video-wrapper relative w-full h-full">
                      <div
                        class="video-poster absolute top-0 left-0 w-full h-full grid place-items-center bg-black z-[2] transition-opacity duration-300"
                        id="videoPoster">
                        <img src="https://img.youtube.com/vi/DxZxS-rGx4E/maxresdefault.jpg" alt="Poster Image"
                          class="w-full h-auto" />
                        <p
                          class="caption absolute right-4 rounded-md backdrop-blur-sm bottom-0 py-2 px-3 bg-black/70 text-white text-lg font-normal cursor-pointer">
                          Fast forward - Siggraph 2021
                        </p>
                        <button
                          class="play-button border inline-block font-bold tracking-wide absolute top-[50%] left-[50%] -translate-y-[50%] -translate-x-[50%] bg-red-500 hover:bg-red-400"
                          id="playButton">
                          Play
                        </button>
                      </div>
                      <iframe class="youtubeVideo w-full h-full z-[2]" src="https://www.youtube.com/embed/DxZxS-rGx4E"
                        frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                  </div>
                </div>
                <div class="embla__slide">
                  <div class="embla__slide__number">
                    <div class="video-wrapper relative w-full h-full">
                      <div
                        class="video-poster absolute top-0 left-0 w-full h-full grid place-items-center bg-black z-[2] transition-opacity duration-300"
                        id="videoPoster">
                        <img src="https://img.youtube.com/vi/-WRjvmP9j-I/maxresdefault.jpg" alt="Poster Image"
                          class="w-full h-auto" />
                        <p
                          class="caption absolute right-4 rounded-md backdrop-blur-sm bottom-0 py-2 px-3 bg-black/70 text-white text-lg font-normal cursor-pointer">
                          Full presentation - Siggraph 2021
                        </p>
                        <button
                          class="play-button border inline-block font-bold tracking-wide absolute top-[50%] left-[50%] -translate-y-[50%] -translate-x-[50%] bg-red-500 hover:bg-red-400"
                          id="playButton">
                          Play
                        </button>
                      </div>
                      <iframe class="youtubeVideo w-full h-full z-[2]" src="https://www.youtube.com/embed/-WRjvmP9j-I"
                        frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                  </div>
                </div>
                <div class="embla__slide">
                  <div class="embla__slide__number">
                    <div class="video-wrapper relative w-full h-full">
                      <div
                        class="video-poster absolute top-0 left-0 w-full h-full grid place-items-center bg-black z-[2] transition-opacity duration-300"
                        id="videoPoster">
                        <img src="https://img.youtube.com/vi/Qospgwhhf0g/maxresdefault.jpg" alt="Poster Image"
                          class="w-full h-auto" />
                        <p
                          class="caption absolute right-4 rounded-md backdrop-blur-sm bottom-0 py-2 px-3 bg-black/70 text-white text-lg font-normal cursor-pointer">
                          Supplementary video
                        </p>
                        <button
                          class="play-button border inline-block font-bold tracking-wide absolute top-[50%] left-[50%] -translate-y-[50%] -translate-x-[50%] bg-red-500 hover:bg-red-400"
                          id="playButton">
                          Play
                        </button>
                      </div>
                      <iframe class="youtubeVideo w-full h-full z-[2]" src="https://www.youtube.com/embed/Qospgwhhf0g"
                        frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                  </div>
                </div>
              </div>
            </div>
            <div class="embla-thumbs">
              <div class="embla-thumbs__viewport">
                <div class="embla-thumbs__container">
                  <div class="embla-thumbs__slide embla-thumbs__slide--selected">
                    <button type="button" class="embla-thumbs__slide__number">
                      <img src="https://img.youtube.com/vi/DxZxS-rGx4E/maxresdefault.jpg" alt=""
                        class="w-full rounded-md" />
                      <div class="bg-black/70 p-2 text-sm absolute bottom-0 font-medium tracking-tight left-0 w-full">
                        Fast Forward
                      </div>
                    </button>
                  </div>
                  <div class="embla-thumbs__slide">
                    <button type="button" class="embla-thumbs__slide__number">
                      <img src="https://img.youtube.com/vi/-WRjvmP9j-I/maxresdefault.jpg" alt=""
                        class="w-full rounded-md" />
                      <div class="bg-black/70 p-2 text-sm absolute bottom-0 font-medium tracking-tight left-0 w-full">
                        Full Talk
                      </div>
                    </button>
                  </div>
                  <div class="embla-thumbs__slide">
                    <button type="button" class="embla-thumbs__slide__number">
                      <img src="https://img.youtube.com/vi/Qospgwhhf0g/maxresdefault.jpg" alt=""
                        class="w-full rounded-md" />
                      <div class="bg-black/70 p-2 text-sm absolute bottom-0 font-medium tracking-tight left-0 w-full">
                        Supp Video
                      </div>
                    </button>
                  </div>
                </div>
              </div>
            </div>
          </div> -->
          <h2 id="Figures" class="py-4">Figures</h2>
          <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-3 [&_figure]:mb-3 [&_figure]:cursor-pointer overflow-hidden">
            <figure style=" border-radius: 5px" data-fancybox="gallery"
              data-caption="Integration of two two-dimensional functions (a), its piecewise-polynomial approximation used as control variate (b, boundaries of each region in green), and the corresponding residual (c, where red and blue are the positive and negative residual, respectively)."
              data-src="./gallery/17.jpg">
              <img src="./gallery/17.jpg" alt="" class="rounded-md w-full h-auto" loading="lazy"/>
            </figure>
            <figure style=" border-radius: 5px" data-fancybox="gallery"
              data-src="./gallery/18.jpg"
              data-caption="Renderings of two purely absorbing media, with high (first row, Hetvol) and low (second row, Smoke) densities, computed using delta tracking, residual ratio tracking, and our adaptive residual ratio tracking (full image). The three methods have approximately the same number of media queries.">
              <img src="./gallery/18.jpg" alt="" class="rounded-md w-full h-auto" loading="lazy"/>
            </figure>


            <figure style=" border-radius: 5px" data-fancybox="gallery" data-caption="Comparison of the different approaches of our technique against Monte Carlo integration for the same number of evaluations of direct illumination. In all cases, Monte Carlo produces noisier images even with MIS. In contrast, our technique leverages MIS adapting the control variate to the integrand, yielding better results both per pixel ('Ours 2D') and for the whole image space ('Ours 4D'). Furthermore, amortizing the control variate among the whole image space reduces noise in low frequency areas, removes structured noise, and serves as antialiasing. All results are calculated using 155 spp.
            " data-src="./gallery/66.jpg">
              <img src="./gallery/66.jpg" alt="" class="rounded-md w-full h-auto" loading="lazy"/>
            </figure>

            <!-- <figure style=" border-radius: 5px" data-fancybox="gallery"
              data-src="https://mcrespo.me/publications/primary-space-cv/figures/fig_multidimensional.jpg"
              data-caption="Comparison between our approach (left column), Monte Carlo, and previous related work in four different scenes (with increasing dimensionality), at equal number of samples (64 spp). The scenes feature several distributed effects including motion blur, depth-of-field and soft shadows. In all cases, Monte Carlo produces renders with high variance, while Hachisuka et al.'s approach achieves good results in smooth domains, but tends to overblur the sharp regions of the scene. In contrast, our unbiased method outperforms previous work keeping the high contrast areas sharp.">
              <img src="https://mcrespo.me/publications/primary-space-cv/figures/fig_multidimensional.jpg" alt=""
                class="rounded-md w-full h-auto" />
            </figure> -->
         


            <figure style=" border-radius: 5px" data-fancybox="gallery"
              data-src="./gallery/64.jpg"
              data-caption="Equal-samples (64 spp) comparison between Monte Carlo, Simpson-Trapezoid quadrature and our technique for computing single scattering from a point light source in isotropic homogenous media. Our technique yields more accurate results and recovers both the smooth global structure of light transport and the high frequency details of the scene, while remaining unbiased.">
              <img src="./gallery/64.jpg" alt="" class="rounded-md w-full h-auto" loading="lazy"/>
            </figure>
         
            <figure style=" border-radius: 5px" data-fancybox="gallery"
              data-caption="Equal-samples (64 spp) comparison between Monte Carlo and our technique for computing two-bounce scattering from a collimated beam in isotropic homogenous media. While pure Monte Carlo generates high-frequency noise, our approach excels at the smooth regions, accurately handling the sharp details."
              data-src="./gallery/65.jpg">
              <img src="./gallery/65.jpg" alt="" class="rounded-md w-full h-auto" loading="lazy"/>
            </figure>
          </div>
          <h2 id="Figures" class="pt-8">Bibtex</h2>
          <div class="code-container">
            <div class="copy-btn"><i class="fa-regular fa-copy"></i></div>
            <pre class="mb-0">
            <code>@misc{morais2024localizationdigitaltwinmimo,
              title={Localization in Digital Twin MIMO Networks: A Case for Massive Fingerprinting}, 
              author={João Morais and Ahmed Alkhateeb},
              year={2024},
              eprint={2403.09614},
              archivePrefix={arXiv},
              primaryClass={cs.IT},
              url={https://arxiv.org/abs/2403.09614}, 
        }</code>
        </pre>
          </div>

          <h2 id="Acknowledgements">Acknowledgements</h2>

          <p style="
                text-align: justify;
                text-indent: 1.5rem;
                margin: 0px 0px 0.5rem;
              ">
            We thank Ibón Guillén for comments and discussion throughout the
            project; Manuel Lagunas for help with figures; Diego Gutierrez for
            advice on the reviews; Felix Bernal for helping with the Single
            Scattering implementation; all the members of the Graphics &amp;
            Imaging Lab that helped with proof-reading; and the reviewers for
            the in-depth reviews. The Pool and Chess are by Hachisuka et al.;
            Cornell Box, House, Classroom and MIS Test are by Benedikt
            Bitterli; Violin was modeled by Tahseen; Helicopter was modeled by
            Mond; Volley Balls models by Shri; Dragon and Budha are from the
            Stanford 3D Scanning Repository; Bistro was modelled by Amazon
            Lumberyard. Lightfields used in Figure 4 are courtesy of
            <a href="http://giga.cps.unizar.es/~ajarabo/pubs/lfeiSIG14/">Jarabo et al. [2014]</a>. This project has been
            funded by the European Research Council
            (ERC) under the EU's Horizon 2020 research and innovation
            programme (project CHAMELEON, grant No 682080), DARPA (project
            REVEAL, HR0011-16-C-0025) and the Spanish Ministry of Economy and
            Competitiveness (project TIN2016-78753-P and
            PID2019-105004GB-I00).
          </p>
        </section>
      </div>
    </main>
  </div>
  <!-- BG -->
  <div id="bg" class="publications"></div>

  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.umd.js"></script>
  <script src="https://unpkg.com/embla-carousel/embla-carousel.umd.js"></script>
  <!-- <script src="../../assets/js/main.js"></script> -->
  <script src="../../assets/js/publication.js"></script>
  <script>
    document.querySelectorAll(".play-button").forEach(function (button) {
      button.addEventListener("click", function () {
        // Remove autoplay from all videos
        document.querySelectorAll(".youtubeVideo").forEach(function (video) {
          let src = video.src.replace("?autoplay=1", ""); // Remove autoplay if it exists
          video.src = src;
        });
        document.querySelectorAll(".video-poster").forEach(function (poster) {
          poster.style.display = "block";
          poster.style.opacity = "1";
        });

        // Handle the clicked video
        var wrapper = button.closest(".video-wrapper");
        var poster = wrapper.querySelector(".video-poster");
        var video = wrapper.querySelector(".youtubeVideo");

        poster.style.opacity = "0";
        setTimeout(function () {
          poster.style.display = "none";
          video.src += "?autoplay=1"; // Add autoplay to the clicked video
        }, 300); // The duration matches the CSS transition
      });
    });
    const addThumbBtnsClickHandlers = (emblaApiMain, emblaApiThumb) => {
      const slidesThumbs = emblaApiThumb.slideNodes();

      const scrollToIndex = slidesThumbs.map(
        (_, index) => () => emblaApiMain.scrollTo(index)
      );

      slidesThumbs.forEach((slideNode, index) => {
        slideNode.addEventListener("click", scrollToIndex[index], false);
      });

      return () => {
        slidesThumbs.forEach((slideNode, index) => {
          slideNode.removeEventListener("click", scrollToIndex[index], false);
        });
      };
    };

    const addToggleThumbBtnsActive = (emblaApiMain, emblaApiThumb) => {
      const slidesThumbs = emblaApiThumb.slideNodes();

      const toggleThumbBtnsState = () => {
        emblaApiThumb.scrollTo(emblaApiMain.selectedScrollSnap());
        const previous = emblaApiMain.previousScrollSnap();
        const selected = emblaApiMain.selectedScrollSnap();
        slidesThumbs[previous].classList.remove(
          "embla-thumbs__slide--selected"
        );
        slidesThumbs[selected].classList.add("embla-thumbs__slide--selected");
      };

      emblaApiMain.on("select", toggleThumbBtnsState);
      emblaApiThumb.on("init", toggleThumbBtnsState);

      return () => {
        const selected = emblaApiMain.selectedScrollSnap();
        slidesThumbs[selected].classList.remove(
          "embla-thumbs__slide--selected"
        );
      };
    };

    const OPTIONS = {};
    const OPTIONS_THUMBS = {
      containScroll: "keepSnaps",
      dragFree: true,
    };

    const viewportNodeMainCarousel =
      document.querySelector(".embla__viewport");
    const viewportNodeThumbCarousel = document.querySelector(
      ".embla-thumbs__viewport"
    );
    const emblaApiMain = EmblaCarousel(viewportNodeMainCarousel, OPTIONS);
    const emblaApiThumb = EmblaCarousel(
      viewportNodeThumbCarousel,
      OPTIONS_THUMBS
    );

    const removeThumbBtnsClickHandlers = addThumbBtnsClickHandlers(
      emblaApiMain,
      emblaApiThumb
    );
    const removeToggleThumbBtnsActive = addToggleThumbBtnsActive(
      emblaApiMain,
      emblaApiThumb
    );

    emblaApiMain
      .on("destroy", removeThumbBtnsClickHandlers)
      .on("destroy", removeToggleThumbBtnsActive);

    emblaApiThumb
      .on("destroy", removeThumbBtnsClickHandlers)
      .on("destroy", removeToggleThumbBtnsActive);
  </script>
</body>

</html>